{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 3: <i>News or \"News\"</i> - Distinguishing facts from misinformation on Reddit\n",
    "\n",
    "### Notebook #5 for Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning is the process of finding the optimal combination of hyperparameter values that maximize the model's performance on a given task.\n",
    "\n",
    "Different hyperparameter values can significantly impact the model's behavior, leading to underfitting (high bias, oversimplified model) or overfitting (high variance, model too complex for the data). Appropriate hyperparameter settings can help strike the right balance between bias and variance, resulting in better generalization performance on unseen data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Import libraries and data\n",
    "The cleaned CSV of comments scraped from the two subreddits (r/news and r/TheOnion) are read into a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read cleaned csv file into a data frame\n",
    "comments_df = pd.read_csv('../data/03_data_post_EDA.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Prepare data for pipeline model selection \n",
    "A pipeline is a way to chain multiple estimators (preprocessing steps and the final estimator) into a sequence of steps. This allows the entire sequence to be treated as a single unit, making it easier to apply the same preprocessing steps consistently for both training and prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments from r/TheOnion (misinformation) are labelled `1` while comments from r/news (fact) are labelled `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = comments_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df['body_cleaned_lemmatized'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>post_title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>body_cleaned</th>\n",
       "      <th>body_cleaned_lemmatized</th>\n",
       "      <th>comment_length</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>emotional_tone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbgsbi4</td>\n",
       "      <td>t3_jptqj9</td>\n",
       "      <td>t3_jptqj9</td>\n",
       "      <td>As you all celebrate or commiserate, please he...</td>\n",
       "      <td>1</td>\n",
       "      <td>Joe Biden elected president of the United States</td>\n",
       "      <td>news</td>\n",
       "      <td>celebrate commiserate please help us reporting...</td>\n",
       "      <td>celebrate commiserate please help reporting co...</td>\n",
       "      <td>138</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gbhfdv2</td>\n",
       "      <td>t3_jptqj9</td>\n",
       "      <td>t3_jptqj9</td>\n",
       "      <td>Congratulations USA! From Brazil, I hope Bolso...</td>\n",
       "      <td>172</td>\n",
       "      <td>Joe Biden elected president of the United States</td>\n",
       "      <td>news</td>\n",
       "      <td>Congratulations USA Brazil hope Bolsonaro next...</td>\n",
       "      <td>congratulation usa brazil hope bolsonaro next ...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gbgt3me</td>\n",
       "      <td>t3_jptqj9</td>\n",
       "      <td>t3_jptqj9</td>\n",
       "      <td>Fox News just called it a couple minutes ago, ...</td>\n",
       "      <td>8749</td>\n",
       "      <td>Joe Biden elected president of the United States</td>\n",
       "      <td>news</td>\n",
       "      <td>Fox News called couple minutes ago know real</td>\n",
       "      <td>fox news call couple minute ago know real</td>\n",
       "      <td>14</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gbgvvs7</td>\n",
       "      <td>t3_jptqj9</td>\n",
       "      <td>t3_jptqj9</td>\n",
       "      <td>\"You were expecting Nevada to decide the elect...</td>\n",
       "      <td>16552</td>\n",
       "      <td>Joe Biden elected president of the United States</td>\n",
       "      <td>news</td>\n",
       "      <td>You expecting Nevada decide election ME PENNSY...</td>\n",
       "      <td>you expect nevada decide election me pennsylvania</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gbgr8hw</td>\n",
       "      <td>t3_jptqj9</td>\n",
       "      <td>t3_jptqj9</td>\n",
       "      <td>Is it 100% confirmed, as in nothing can take t...</td>\n",
       "      <td>3176</td>\n",
       "      <td>Joe Biden elected president of the United States</td>\n",
       "      <td>news</td>\n",
       "      <td>100 confirmed nothing take away</td>\n",
       "      <td>100 confirm nothing take away</td>\n",
       "      <td>11</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37774</th>\n",
       "      <td>fsm23z4</td>\n",
       "      <td>t1_fslramj</td>\n",
       "      <td>t3_gus9vi</td>\n",
       "      <td>What episode is this?</td>\n",
       "      <td>2</td>\n",
       "      <td>‘Let Them Have Eric,’ Screams Trump While Push...</td>\n",
       "      <td>TheOnion</td>\n",
       "      <td>episode this</td>\n",
       "      <td>episode this</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37775</th>\n",
       "      <td>fsml44n</td>\n",
       "      <td>t1_fslci54</td>\n",
       "      <td>t3_gus9vi</td>\n",
       "      <td>Hahaha!</td>\n",
       "      <td>3</td>\n",
       "      <td>‘Let Them Have Eric,’ Screams Trump While Push...</td>\n",
       "      <td>TheOnion</td>\n",
       "      <td>Hahaha</td>\n",
       "      <td>hahaha</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37776</th>\n",
       "      <td>fsmp2et</td>\n",
       "      <td>t1_fsmfqvz</td>\n",
       "      <td>t3_gus9vi</td>\n",
       "      <td>[Skip to 32:00](https://youtu.be/Wm0EaYEj9AU?t...</td>\n",
       "      <td>6</td>\n",
       "      <td>‘Let Them Have Eric,’ Screams Trump While Push...</td>\n",
       "      <td>TheOnion</td>\n",
       "      <td>Skip 3200 want get straight it miss tear gassi...</td>\n",
       "      <td>skip 3200 want get straight miss tear gas expl...</td>\n",
       "      <td>168</td>\n",
       "      <td>0.084375</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37777</th>\n",
       "      <td>fsm7crj</td>\n",
       "      <td>t1_fsm23z4</td>\n",
       "      <td>t3_gus9vi</td>\n",
       "      <td>[\"The fire\"](https://youtu.be/_u1cbZTwBx4)</td>\n",
       "      <td>6</td>\n",
       "      <td>‘Let Them Have Eric,’ Screams Trump While Push...</td>\n",
       "      <td>TheOnion</td>\n",
       "      <td>The fire</td>\n",
       "      <td>the fire</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37778</th>\n",
       "      <td>fsndoxc</td>\n",
       "      <td>t1_fsm7crj</td>\n",
       "      <td>t3_gus9vi</td>\n",
       "      <td>Thank you, kind sir!</td>\n",
       "      <td>1</td>\n",
       "      <td>‘Let Them Have Eric,’ Screams Trump While Push...</td>\n",
       "      <td>TheOnion</td>\n",
       "      <td>Thank you kind sir</td>\n",
       "      <td>thank you kind sir</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37759 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      comment_id   parent_id    post_id  \\\n",
       "0        gbgsbi4   t3_jptqj9  t3_jptqj9   \n",
       "1        gbhfdv2   t3_jptqj9  t3_jptqj9   \n",
       "2        gbgt3me   t3_jptqj9  t3_jptqj9   \n",
       "3        gbgvvs7   t3_jptqj9  t3_jptqj9   \n",
       "4        gbgr8hw   t3_jptqj9  t3_jptqj9   \n",
       "...          ...         ...        ...   \n",
       "37774    fsm23z4  t1_fslramj  t3_gus9vi   \n",
       "37775    fsml44n  t1_fslci54  t3_gus9vi   \n",
       "37776    fsmp2et  t1_fsmfqvz  t3_gus9vi   \n",
       "37777    fsm7crj  t1_fsm23z4  t3_gus9vi   \n",
       "37778    fsndoxc  t1_fsm7crj  t3_gus9vi   \n",
       "\n",
       "                                                    body  score  \\\n",
       "0      As you all celebrate or commiserate, please he...      1   \n",
       "1      Congratulations USA! From Brazil, I hope Bolso...    172   \n",
       "2      Fox News just called it a couple minutes ago, ...   8749   \n",
       "3      \"You were expecting Nevada to decide the elect...  16552   \n",
       "4      Is it 100% confirmed, as in nothing can take t...   3176   \n",
       "...                                                  ...    ...   \n",
       "37774                              What episode is this?      2   \n",
       "37775                                            Hahaha!      3   \n",
       "37776  [Skip to 32:00](https://youtu.be/Wm0EaYEj9AU?t...      6   \n",
       "37777         [\"The fire\"](https://youtu.be/_u1cbZTwBx4)      6   \n",
       "37778                               Thank you, kind sir!      1   \n",
       "\n",
       "                                              post_title subreddit  \\\n",
       "0       Joe Biden elected president of the United States      news   \n",
       "1       Joe Biden elected president of the United States      news   \n",
       "2       Joe Biden elected president of the United States      news   \n",
       "3       Joe Biden elected president of the United States      news   \n",
       "4       Joe Biden elected president of the United States      news   \n",
       "...                                                  ...       ...   \n",
       "37774  ‘Let Them Have Eric,’ Screams Trump While Push...  TheOnion   \n",
       "37775  ‘Let Them Have Eric,’ Screams Trump While Push...  TheOnion   \n",
       "37776  ‘Let Them Have Eric,’ Screams Trump While Push...  TheOnion   \n",
       "37777  ‘Let Them Have Eric,’ Screams Trump While Push...  TheOnion   \n",
       "37778  ‘Let Them Have Eric,’ Screams Trump While Push...  TheOnion   \n",
       "\n",
       "                                            body_cleaned  \\\n",
       "0      celebrate commiserate please help us reporting...   \n",
       "1      Congratulations USA Brazil hope Bolsonaro next...   \n",
       "2           Fox News called couple minutes ago know real   \n",
       "3      You expecting Nevada decide election ME PENNSY...   \n",
       "4                        100 confirmed nothing take away   \n",
       "...                                                  ...   \n",
       "37774                                       episode this   \n",
       "37775                                             Hahaha   \n",
       "37776  Skip 3200 want get straight it miss tear gassi...   \n",
       "37777                                           The fire   \n",
       "37778                                 Thank you kind sir   \n",
       "\n",
       "                                 body_cleaned_lemmatized  comment_length  \\\n",
       "0      celebrate commiserate please help reporting co...             138   \n",
       "1      congratulation usa brazil hope bolsonaro next ...              12   \n",
       "2              fox news call couple minute ago know real              14   \n",
       "3      you expect nevada decide election me pennsylvania              13   \n",
       "4                          100 confirm nothing take away              11   \n",
       "...                                                  ...             ...   \n",
       "37774                                       episode this               4   \n",
       "37775                                             hahaha               1   \n",
       "37776  skip 3200 want get straight miss tear gas expl...             168   \n",
       "37777                                           the fire               2   \n",
       "37778                                 thank you kind sir               4   \n",
       "\n",
       "       sentiment_score emotional_tone  \n",
       "0             0.150000        Neutral  \n",
       "1             0.000000        Neutral  \n",
       "2             0.200000        Neutral  \n",
       "3             0.000000        Neutral  \n",
       "4             0.400000       Positive  \n",
       "...                ...            ...  \n",
       "37774         0.000000        Neutral  \n",
       "37775         0.250000        Neutral  \n",
       "37776         0.084375        Neutral  \n",
       "37777         0.000000        Neutral  \n",
       "37778         0.750000       Positive  \n",
       "\n",
       "[37759 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37774</th>\n",
       "      <td>1</td>\n",
       "      <td>TheOnion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37775</th>\n",
       "      <td>1</td>\n",
       "      <td>TheOnion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37776</th>\n",
       "      <td>1</td>\n",
       "      <td>TheOnion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37777</th>\n",
       "      <td>1</td>\n",
       "      <td>TheOnion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37778</th>\n",
       "      <td>1</td>\n",
       "      <td>TheOnion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37759 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label subreddit\n",
       "0          0      news\n",
       "1          0      news\n",
       "2          0      news\n",
       "3          0      news\n",
       "4          0      news\n",
       "...      ...       ...\n",
       "37774      1  TheOnion\n",
       "37775      1  TheOnion\n",
       "37776      1  TheOnion\n",
       "37777      1  TheOnion\n",
       "37778      1  TheOnion\n",
       "\n",
       "[37759 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## binary label:  1 - misinformation / TheOnion, 0 - fact / news\n",
    "comments_df['label'] = comments_df['subreddit'].map({'TheOnion':1, 'news':0})\n",
    "comments_df[['label','subreddit']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    0.528881\n",
       "1    0.471119\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up X and y\n",
    "X = comments_df['body_cleaned_lemmatized']\n",
    "y = comments_df['label']\n",
    "\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`stratify = y` replicates similar distribution of the classes pre-train/test split. This means that the train-test split algorithm will try to preserve the class proportions in both the training and test sets, ensuring that they are representative of the overall dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split our data into training and testing sets.\n",
    "# set a custom test size of 20% for model evaluation. \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Find the best fit\n",
    "`GridSearchCV` is a technique for automatically tuning the hyperparameters of a machine learning model. It defines a grid of hyperparameter values to explore, training the model with each combination of hyperparameters using cross-validation, and evaluating the model's performance using specified metrics (e.g., accuracy, sensitivity, F1-score).\n",
    "\n",
    "Pipeline is chained together with the transformers or pre-processing steps (e.g. standardScaler, countVectorizer, etc.) and the estimator or model (e.g. kNN, LogisticRegression, NB, etc.).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1a: Instantiate pipeline and `GridSearchCV`\n",
    "1. Define the Pipeline, by instantiating the `Pipeline()` class. Arguments to the class initiator are the \"tasks\" (e.g. vectorize, scaling, model) to be carried out in order. Pipeline is chained together with the Transformers and Estimator. \n",
    "2. Define the hyperparameters in a dictionary. Hyperparameters are the set of test parameters to be used by GridSearch. \n",
    "   - For each hyperparameter, go with the format `\"<task_name>_ _ <parameter_name>\" : [ <param1>, <param2>, <param3>,...]`\n",
    "3. Instantiate a GridSearch for the Pipeline (defined in #1). \n",
    "   - First argument is the pipeline name\n",
    "   - `param_grid` is the name of the hyperparameter dictionary defined in #2 \n",
    "   - `scoring=recall` since we are trying to optimise sensitivity\n",
    "   - `cv=5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2, SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline #1:\n",
    "# 1. CountVectorizer (transformer)\n",
    "# 2. Multinomial Naive Bayes (estimator)\n",
    "pipe_cv_mnb = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# define dictionary of hyperparameters spanning both transformers and estimators\n",
    "pipe_cv_mnb_param = {\n",
    "    'cvec__max_features': [1000,],\n",
    "    'cvec__stop_words': [None,'english'],\n",
    "    'cvec__min_df': [2, 5, 10],\n",
    "    'cvec__max_df': [0.5, 0.7, 0.9],\n",
    "    'cvec__ngram_range': [(1,1),(1,2)],\n",
    "    'nb__alpha': [0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "# instantiate our GridSearchCV object\n",
    "gs_cv_mnb = GridSearchCV(pipe_cv_mnb, \n",
    "                        param_grid=pipe_cv_mnb_param,\n",
    "                        scoring='recall', \n",
    "                        cv=5)\n",
    "\n",
    "# Pipeline #2:\n",
    "# 1. CountVectorizer (transformer)\n",
    "# 2. Logistic Regression (estimator)\n",
    "pipe_cv_lr = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('feature_selection', SelectKBest(chi2, k=1000)),\n",
    "    ('lr', LogisticRegression(solver='liblinear', max_iter=2000, random_state=42))\n",
    "])\n",
    "\n",
    "# define dictionary of hyperparameters spanning both transformers and estimators\n",
    "pipe_cv_lr_param = {\n",
    "    'cvec__max_features': [2000,7500],\n",
    "    'cvec__stop_words': [None,'english'],\n",
    "    'cvec__min_df': [1,10],\n",
    "    'cvec__max_df': [0.1,0.9],\n",
    "    'cvec__ngram_range': [(1,1),(1,2)],\n",
    "    'lr__C': [0.01, 1.0, 10],\n",
    "    'lr__penalty' : ['l1', 'l2'],\n",
    "    'lr__class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# instantiate our GridSearchCV object\n",
    "gs_cv_lr = GridSearchCV(pipe_cv_lr, \n",
    "                        param_grid=pipe_cv_lr_param, \n",
    "                        scoring='recall',\n",
    "                        cv=5)\n",
    "\n",
    "# Pipeline #3:\n",
    "# 1. TF-IDF Vectorizer (transformer)\n",
    "# 2. Multinomial Naive Bayes (estimator)\n",
    "pipe_tv_mnb = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# define dictionary of hyperparameters spanning both transformers and estimators\n",
    "pipe_tv_mnb_param = {\n",
    "    'tvec__max_features': [1000, 5000, 10000],\n",
    "    'tvec__stop_words': [None,'english'],\n",
    "    'tvec__min_df': [2, 5, 10],\n",
    "    'tvec__max_df': [0.1, 0.9],\n",
    "    'tvec__ngram_range': [(1,1),(1,2)],\n",
    "    'nb__alpha': [0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "# instantiate our GridSearchCV object\n",
    "gs_tv_mnb = GridSearchCV(pipe_tv_mnb, \n",
    "                        param_grid=pipe_tv_mnb_param, \n",
    "                        scoring='recall',\n",
    "                        cv=5)\n",
    "\n",
    "# Pipeline #4:\n",
    "# 1. TF-IDF Vectorizer (transformer)\n",
    "# 2. Logistic Regression (estimator)\n",
    "pipe_tv_lr = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('lr', LogisticRegression(solver='liblinear', max_iter=2000, random_state=42))\n",
    "])\n",
    "\n",
    "# define dictionary of hyperparameters spanning both transformers and estimators\n",
    "pipe_tv_lr_param = {\n",
    "    'tvec__max_features': [1000, 5000, 10000],\n",
    "    'tvec__stop_words': [None,'english'],\n",
    "    'tvec__min_df': [2, 5, 10],\n",
    "    'tvec__max_df': [0.5, 0.7, 0.9],\n",
    "    'tvec__ngram_range': [(1,1), (1,2)],\n",
    "    'lr__C': [0.01, 1.0, 10],\n",
    "    'lr__penalty' : ['l1', 'l2']\n",
    "}\n",
    "\n",
    "# instantiate our GridSearchCV object\n",
    "gs_tv_lr = GridSearchCV(pipe_tv_lr, \n",
    "                        param_grid=pipe_tv_lr_param, \n",
    "                        scoring='recall',\n",
    "                        cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1b: Add the newly configured `GridSearchCV` into the `grids` dictionary\n",
    "- For each GridSearchCV object, assign an `id` (running number) which is the key in the dictionary.\n",
    "- For each `id` key, the corresponding value is a dictionary.\n",
    "    - `grid_search_obj` carries the object name of the GridSearchCV.\n",
    "    - `grid_search_desc` is a description of the gridSearch, for user-friendly display in the report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids = {\n",
    "    1 : {\n",
    "        \"grid_search_obj\": gs_cv_mnb,\n",
    "        \"grid_search_desc\" : \"MultinomialNB with CountVectorizer\",\n",
    "    },\n",
    "\n",
    "    2 : {\n",
    "        \"grid_search_obj\": gs_cv_lr,\n",
    "        \"grid_search_desc\" : \"LogisticRegression with CountVectorizer\",\n",
    "    },\n",
    "\n",
    "    3 : {\n",
    "        \"grid_search_obj\": gs_tv_mnb,\n",
    "        \"grid_search_desc\" : \"MultinomialNB with TfidfVectorizer\",\n",
    "    },\n",
    "\n",
    "    4 : {\n",
    "        \"grid_search_obj\": gs_tv_lr,\n",
    "        \"grid_search_desc\" : \"LogisticRegression with TfidfVectorizer\",\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Execute the GridSearch\n",
    "In the `grid_execute` list, specify which GridSearch `id` to be execute. \n",
    "- for all GridSearch `id` defined in the `grids` dictionary, the list of GridSearch will be executed. \n",
    "- if keyword \"**ALL**\" is provided, then all the `id` in the `grids` dictionary will be pulled, which mean all the defined GridSearch will be executed in one go. \n",
    "\n",
    "In the interest of time, and with reference to 04_Data_Modelling notebook, since `LogisticRegression` with `CountVectorizer` provided the best balance of accuracy, sensitivity and f1-score, we will execute `GridSearchCV` only for `LogisticRegression with CountVectorizer`.\n",
    "\n",
    "| Model | Accuracy | Precision | Sensitivity | F1 Score |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| `LogisticRegression with CountVectorizer` | 0.768 | 0.742 | 0.780 | 0.760 |\n",
    "\n",
    "Note: `gs_result` is the dictionary that holds the grid search outcome for every execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>>Estimator: %s LogisticRegression with CountVectorizer\n",
      "Best params: {'cvec__max_df': 0.1, 'cvec__max_features': 7500, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': 'english', 'lr__C': 1.0, 'lr__class_weight': 'balanced', 'lr__penalty': 'l1'}\n",
      "Best training accuracy: 0.837\n",
      "{'best_score': 0.8371867811687217, 'best_param': {'cvec__max_df': 0.1, 'cvec__max_features': 7500, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': 'english', 'lr__C': 1.0, 'lr__class_weight': 'balanced', 'lr__penalty': 'l1'}, 'train_score': 0.8565807040966903, 'test_score': 0.8451377178189995, 'accuracy_score': 0.795948093220339, 'm_tn': 3004, 'm_fp': 990, 'm_fn': 551, 'm_tp': 3007, 'm_sensitivity': 0.8451377178189995, 'm_precision': 0.7523142356767576, 'm_specificity': 0.7521281922884326, 'm_negative_predictive_value': 0.8450070323488045, 'm_accuracy': 0.795948093220339, 'm_f1_score': 0.7960291197882198}\n",
      "\n",
      "\n",
      " ****** RESULT ********* \n",
      "\n",
      " Best performing model - LogisticRegression with CountVectorizer, with score 0.8371867811687217\n"
     ]
    }
   ],
   "source": [
    "### Specify the GridSearch `id` to be executed, in the `grid_execute` list \n",
    "#   ALWAYS IN A LIST, even if only single `id` is given.             \n",
    "#   Keyword \"ALL\" will auto populate all the `id` from the `grids` dictionary into the lst                 \n",
    "#################################\n",
    "grid_execute = [2, ] # only execute GridSearch for LogisticRegression with CVec\n",
    "# grid_execute = [\"ALL\",]\n",
    "#################################\n",
    "\n",
    "# initiate variable, do not tamper # \n",
    "best_acc = 0.0\n",
    "best_idx = 0\n",
    "best_gs = ''\n",
    "gs_result = {}\n",
    "gs_execute = []\n",
    "\n",
    "# pull out list of grid `id` for execution \n",
    "for ge in grid_execute:\n",
    "\tif len(grid_execute) == 1 and ge == \"ALL\":\n",
    "\t\tfor i_, grid_cfg in grids.items():\n",
    "\t\t\tgs_execute.append(grid_cfg)\n",
    "\telse:\n",
    "\t\tgs_execute.append(grids[ge])\n",
    "\n",
    "# GridSearch execution based on the defined list of `id`\n",
    "for idx, ge in enumerate(gs_execute):\n",
    "\tgs = ge['grid_search_obj']\n",
    "\tgs_desc = ge['grid_search_desc']\n",
    "\tprint('\\n>>>>Estimator: %s', gs_desc)\t\n",
    "\t# Fit grid search\t\n",
    "\tgs.fit(X_train, y_train)\n",
    "\t# Best params\n",
    "\tprint('Best params: %s' % gs.best_params_)\n",
    "\t# Best training data accuracy\n",
    "\tprint('Best training accuracy: %.3f' % gs.best_score_)\n",
    "\n",
    "\tgs_result[gs_desc] = {}\n",
    "\tgs_result[gs_desc]['best_score'] = gs.best_score_\n",
    "\tgs_result[gs_desc]['best_param'] = gs.best_params_\n",
    "\tgs_result[gs_desc]['train_score'] = gs.score(X_train, y_train)\n",
    "\tgs_result[gs_desc]['test_score'] = gs.score(X_test, y_test)\n",
    "\t\n",
    "\t# Predict on test data with best params\n",
    "\ty_pred = gs.predict(X_test)\n",
    "\tgs_result[gs_desc]['accuracy_score'] = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\ttn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\tgs_result[gs_desc]['m_tn'] = tn\n",
    "\tgs_result[gs_desc]['m_fp'] = fp\n",
    "\tgs_result[gs_desc]['m_fn'] = fn\n",
    "\tgs_result[gs_desc]['m_tp'] = tp\n",
    "\tgs_result[gs_desc]['m_sensitivity'] = tp / (tp+fn)\n",
    "\tgs_result[gs_desc]['m_precision'] = tp / (tp+fp)\n",
    "\tgs_result[gs_desc]['m_specificity'] = tn / (tn +fp)\n",
    "\tgs_result[gs_desc]['m_negative_predictive_value'] = tn / (tn +fn)\n",
    "\tgs_result[gs_desc]['m_accuracy'] = (tp +tn) / (tp +tn+fp+fn)\n",
    "\tgs_result[gs_desc]['m_f1_score'] = 2*tp / (2*tp + fp + fn)\n",
    "\n",
    "\tif gs.best_score_ > best_acc:\n",
    "\t\tbest_acc = gs.best_score_\n",
    "\t\tbest_gs = gs_desc\n",
    "\t\n",
    "\n",
    "\tprint(gs_result[gs_desc])\n",
    "\n",
    "print(f\"\\n\\n ****** RESULT ********* \\n\\n Best performing model - {best_gs}, with score {best_acc}\")\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Examine the results of GridSearch\n",
    "- GridSearch results are captured in the `gs_result` dataframe for easier reading. \n",
    "- `gs_result` is exported into CSV for recording.\n",
    "\n",
    "Once the GridSearch has fit, we interpret the following information from the GridSearch object as follows :\n",
    "\n",
    "| Property | Description |\n",
    "| --- | ---|\n",
    "| **`best_param`** | The hyperparameters that have been found to perform with the best score. |\n",
    "| **`best_score`** | Best mean cross-validated score achieved. |\n",
    "| **`m_accuracy`** | Measures the overall correctness of the model's predictions, regardless of class. |\n",
    "| **`m_f1_score`** | Balanced measure of precision and recall, considering both false positives and false negatives. |\n",
    "| **`m_negative_predictive_value`** | Measures the proportion of correctly identified true negative cases (correctly identifying facts as not misinformation) among all instances that are predicted as negative. |\n",
    "| **`m_precision`** | Measures the proportion of correctly identified misinformation among all instances predicted as misinformation. |\n",
    "| **`m_sensitivity`** | Measures the proportion of actual misinformation that is correctly identified by the model. |\n",
    "| **`m_specificity`** | Measures the proportion of actual facts that are correctly identified by the model. |\n",
    "\n",
    "In our study, we would like to optimise sensitivity and F1 score simultaneously to achieve the best performance in identifying misinformation while minimizing the misclassification of facts as misinformation. As sensitivity increases, precision tends to decrease.\n",
    "\n",
    "Since F1 score is a measure of both sensitivity and precision, F1 score also tends to decrease as sensitivity increases. Hence, we should try to achieve a balanced optimisation of both sensitivity and F1 score to ensure a greater weight on sensitivity is placed over precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression with CountVectorizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy_score</th>\n",
       "      <td>0.795948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_param</th>\n",
       "      <td>{'cvec__max_df': 0.1, 'cvec__max_features': 75...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_score</th>\n",
       "      <td>0.837187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m_accuracy</th>\n",
       "      <td>0.795948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m_f1_score</th>\n",
       "      <td>0.796029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m_fn</th>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m_fp</th>\n",
       "      <td>990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m_negative_predictive_value</th>\n",
       "      <td>0.845007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m_precision</th>\n",
       "      <td>0.752314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m_sensitivity</th>\n",
       "      <td>0.845138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m_specificity</th>\n",
       "      <td>0.752128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m_tn</th>\n",
       "      <td>3004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m_tp</th>\n",
       "      <td>3007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_score</th>\n",
       "      <td>0.845138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.856581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       LogisticRegression with CountVectorizer\n",
       "accuracy_score                                                        0.795948\n",
       "best_param                   {'cvec__max_df': 0.1, 'cvec__max_features': 75...\n",
       "best_score                                                            0.837187\n",
       "m_accuracy                                                            0.795948\n",
       "m_f1_score                                                            0.796029\n",
       "m_fn                                                                       551\n",
       "m_fp                                                                       990\n",
       "m_negative_predictive_value                                           0.845007\n",
       "m_precision                                                           0.752314\n",
       "m_sensitivity                                                         0.845138\n",
       "m_specificity                                                         0.752128\n",
       "m_tn                                                                      3004\n",
       "m_tp                                                                      3007\n",
       "test_score                                                            0.845138\n",
       "train_score                                                           0.856581"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_result= pd.DataFrame(gs_result).T\n",
    "#gs_df = gs_df.reset_index().rename(columns={\"index\":\"model\"})\n",
    "gs_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to print gs_result data frame into a csv file\n",
    "# grid_search_result_csv = model_ready_csv[:-4]+'_RESULT_'+datetime.now().strftime(\"%Y%m%d%H%M\")+'.csv'\n",
    "# gs_result.to_csv(f'../data/'+grid_search_result_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
